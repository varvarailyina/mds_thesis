{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS Thesis\n",
    "#### 01. Pre-process the PARTYPRESS data\n",
    "\n",
    "<br>\n",
    "<hr style=\"opacity: 0.5\">\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/varvarailyina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from datasets import Dataset\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check wd\n",
    "os.getcwd()\n",
    "#os.chdir(\"/Users/varvarailyina/hertie/mds_thesis/scripts/\")\n",
    "\n",
    "# load labels data\n",
    "df_partypress = pd.read_csv(\"../data/in/partypress/csv/partypress.csv\")\n",
    "\n",
    "# load text data\n",
    "df_texts = pd.read_csv(\"../data/in/partypress/csv/partypress_texts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"opacity: 0.5\">\n",
    "\n",
    "### Pre-process data\n",
    "\n",
    "-- *Merge PARTYPRESS datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check indices\n",
    "print(df_partypress.index.is_unique)\n",
    "print(df_texts.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set merging index to be 'id'\n",
    "df_partypress.set_index('id', inplace=True)\n",
    "df_texts.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets based on id and country_name\n",
    "df = df_partypress.merge(df_texts, on=['id', 'country_name'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country_name', 'parlgov_id', 'party', 'party_name',\n",
      "       'party_name_english', 'family_name', 'date', 'month', 'month_start',\n",
      "       'month_end', 'calendar_week', 'week_start', 'week_end', 'header',\n",
      "       'issue_multi', 'issue_mono', 'issue', 'issue_coder2', 'position',\n",
      "       'position_coder2', 'cv_sample', 'issue_ridge', 'issue_super', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check var names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- *Filter data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for germany\n",
    "df_de = df[df['country_name'] == 'germany']\n",
    "\n",
    "# filter out press releases with no issue (use Monolingual Transformer)\n",
    "df_de = df_de[df_de['issue_mono'].isin([98, 99]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43685 entries, 18021 to 10366\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   country_name        43685 non-null  object \n",
      " 1   parlgov_id          43685 non-null  float64\n",
      " 2   party               43685 non-null  object \n",
      " 3   party_name          43685 non-null  object \n",
      " 4   party_name_english  43685 non-null  object \n",
      " 5   family_name         43685 non-null  object \n",
      " 6   date                43685 non-null  object \n",
      " 7   month               43685 non-null  int64  \n",
      " 8   month_start         43685 non-null  object \n",
      " 9   month_end           43685 non-null  object \n",
      " 10  calendar_week       43685 non-null  int64  \n",
      " 11  week_start          43685 non-null  object \n",
      " 12  week_end            43685 non-null  object \n",
      " 13  header              43685 non-null  object \n",
      " 14  issue_multi         43685 non-null  int64  \n",
      " 15  issue_mono          43685 non-null  int64  \n",
      " 16  issue               2528 non-null   float64\n",
      " 17  issue_coder2        332 non-null    float64\n",
      " 18  position            2519 non-null   float64\n",
      " 19  position_coder2     315 non-null    float64\n",
      " 20  cv_sample           43685 non-null  int64  \n",
      " 21  issue_ridge         43685 non-null  int64  \n",
      " 22  issue_super         43685 non-null  int64  \n",
      " 23  text                43685 non-null  object \n",
      "dtypes: float64(5), int64(7), object(12)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_de.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .csv\n",
    "df_de.to_csv(\"../data/out/df_de.csv\", index=False)\n",
    "\n",
    "# load `df_de` data\n",
    "#df_de = pd.read_csv(\"../data/out/df_de.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- *Sample data (remove this later)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 1000 press releases\n",
    "#df_sample = df_de.sample(n=1000, random_state=42)\n",
    "\n",
    "# randomly select 8800 press releases\n",
    "df_sample = df_de.sample(n=8800, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anlässlich der aktuellen Entwicklungen in der Syrien-Krise erklärt der Vorsitzende SPD-Bundestagsfraktion Frank-Walter Steinmeier:   Es ist ein Hoffnungsschimmer in letzter Minute. Innerhalb von nur 24 Stunden haben Äußerungen von US-Außenminister Kerry, seinem russischen Kollegen Lawrow und dem syrischen Außenminister al-Muallim einen Ausweg aus der scheinbar unausweichlichen militärischen Logik gewiesen. Nachdem inzwischen auch Präsident Obama sich offen für den russischen Vorstoß gezeigt hat, muss die syrische Führung jetzt ihre ernsthafte Kooperationsbereitschaft unter Beweis stellen. Dabei ist die russische Regierung gefragt, ihren gesamten Einfluss geltend zu machen, um die syrischen Chemiewaffen unter internationale Kontrolle zu stellen. Dazu muss sich die internationale Staatengemeinschaft unter Führung der USA und Russlands jetzt auf ein konkretes und verifizierbares Verfahren mit verbindlichen Zeitplänen und Sanktionsmechanismen verständigen. Der UN-Sicherheitsrat muss hierüber in einer neuen UN-Resolution entscheiden und zugleich die UN-Inspekteure mit einem klaren Mandat ausstatten, um weiter nach Beweisen für die Urheberschaft der Angriffe vom 21.08. zu suchen. Die Verantwortlichen für den Giftgasangriff müssen ermittelt und zur Rechenschaft gezogen werden. Am Anfang des Prozesses muss eine mindestens 72stündige Waffenruhe stehen, eine humanitäre Atempause, die es erlaubt, dringend notwendige Hilfe auch in den Regionen zu leisten, die wegen anhaltender Kämpfe bislang nicht erreichbar waren. Die neue Wendung muss gleichzeitig genutzt werden, um endlich den Einstieg in eine politische Lösung des Konfliktes zu schaffen. Nur so kann das Blutvergießen in Syrien beendet werden. Die Vorbereitungen für eine zweite Syrien-Konferenz mit Beteiligung aller wichtigen regionalen Kräfte inklusive Irans müssen deshalb mit allem Nachdruck vorangetrieben werden. Es ist bedauerlich, dass die Bundesregierung sich durch ihren Schlingerkurs in den letzten Tagen um jede Glaubwürdigkeit gebracht hat. Gerade jetzt bräuchte es eine deutsche Außenpolitik, die in Washington und Moskau über Gewicht und Ansehen verfügt. Für die Suche nach politischen Lösungen für den syrischen Bürgerkrieg ist das ein schweres Handicap.\n"
     ]
    }
   ],
   "source": [
    "# look at a press release\n",
    "print(df_sample['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- *Split press releases into sentences*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to split press releases into sentences\n",
    "def explode_sentences(df, text_col='text'):\n",
    "    \n",
    "    # apply sentence splitting\n",
    "    df['sentences'] = df[text_col].apply(sent_tokenize)\n",
    "    \n",
    "    # each sentence gets its own row\n",
    "    df_exploded = df.explode('sentences').reset_index(drop=True)\n",
    "    \n",
    "    # rename column\n",
    "    df_exploded = df_exploded.rename(columns={'sentences': 'sentence'})\n",
    "    \n",
    "    return df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function\n",
    "#df_sentences = explode_sentences(df_de)\n",
    "df_sentences = explode_sentences(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .csv\n",
    "df_sentences.to_csv(\"../data/out/df_sentences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- *Extract only sentence text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sentence text\n",
    "sentences = list(df_sentences['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sentence data as .pkl file\n",
    "with open('../data/out/sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- *ARCHIVE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process texts df\n",
    "#texts = df_de['text'].dropna()\n",
    "texts = df_sample['text'].dropna()\n",
    "text_df = texts.to_frame()\n",
    "\n",
    "# convert df to dataset\n",
    "dataset = Dataset.from_pandas(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to disk\n",
    "dataset.save_to_disk(\"../data/out/dataset/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
