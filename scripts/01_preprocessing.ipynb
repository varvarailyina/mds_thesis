{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS Thesis\n",
    "#### 01 Pre-processing\n",
    "\n",
    "<hr style=\"opacity: 0.5\">\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install if needed\n",
    "#!pip install transformers\n",
    "\n",
    "# load libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['könnte',\n",
       " 'unsere',\n",
       " 'einem',\n",
       " 'ins',\n",
       " 'ihre',\n",
       " 'aber',\n",
       " 'unser',\n",
       " 'hin',\n",
       " 'manchen',\n",
       " 'um']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually downloaded german stopwords (in terminal)\n",
    "#python -m nltk.downloader stopwords punkt\n",
    "\n",
    "# find location of nltk data\n",
    "#print(nltk.data.path)\n",
    "\n",
    "# set path to nltk data\n",
    "nltk.data.path.append(\"/Users/varvarailyina/nltk_data/corpora/stopwords\")\n",
    "\n",
    "# import german stopwords\n",
    "stop_words = set(stopwords.words(\"german\"))\n",
    "\n",
    "# output first 10\n",
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/varvarailyina/hertie/mds_thesis/scripts'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set wd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load monthly data\n",
    "df_monthly = pd.read_csv(\"../data/in/partypress/csv/monthly_agendas.csv\")\n",
    "#df_monthly = df_monthly[df_monthly[\"issue\"] == 9]\n",
    "\n",
    "# load partypress data\n",
    "df_partypress = pd.read_csv(\"../data/in/partypress/csv/partypress.csv\")\n",
    "\n",
    "# load texts data\n",
    "df_texts = pd.read_csv(\"../data/in/partypress/csv/partypress_texts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"opacity: 0.2\">\n",
    "\n",
    "### Data pre-processing\n",
    "\n",
    "#### 1. clean data, merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data for germany\n",
    "df_issues = df_partypress[df_partypress[\"country_name\"] == \"germany\"]\n",
    "df_texts = df_texts[df_texts[\"country_name\"] == \"germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>id</th>\n",
       "      <th>party</th>\n",
       "      <th>date</th>\n",
       "      <th>month_start</th>\n",
       "      <th>month_end</th>\n",
       "      <th>month</th>\n",
       "      <th>calendar_week</th>\n",
       "      <th>week_start</th>\n",
       "      <th>week_end</th>\n",
       "      <th>issue_ridge</th>\n",
       "      <th>issue_super</th>\n",
       "      <th>header</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany</td>\n",
       "      <td>18020</td>\n",
       "      <td>FDP</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>Marc Jungnickel neuer Pressesprecher der FDP-B...</td>\n",
       "      <td>. Die Vorsitzende der FDP-Bundestagsfraktion B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>germany</td>\n",
       "      <td>18021</td>\n",
       "      <td>FDP</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Steinmeier leidet an Politikamnesie</td>\n",
       "      <td>. Zu den heutigen Äußerungen von SPD-Fraktions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>germany</td>\n",
       "      <td>18042</td>\n",
       "      <td>FDP</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nur Entlastung garantiert Erfolg bei Bekämpfun...</td>\n",
       "      <td>. Zu den aktuellen Arbeitslosenzahlen erklärt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germany</td>\n",
       "      <td>18065</td>\n",
       "      <td>FDP</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>Westbalkan und Türkei müssen ihre Beitrittsper...</td>\n",
       "      <td>. Zu dem Vorstoß der CSU-Landesgruppe, die Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>germany</td>\n",
       "      <td>18083</td>\n",
       "      <td>FDP</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Die Sechsjährige Grundschule ist kein Erfolgsm...</td>\n",
       "      <td>. Zu den Äußerungen des Hamburger Bürgermeiste...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name     id party        date month_start   month_end  month  \\\n",
       "0      germany  18020   FDP  2010-01-04  2010-01-01  2010-01-31   1001   \n",
       "1      germany  18021   FDP  2010-01-04  2010-01-01  2010-01-31   1001   \n",
       "2      germany  18042   FDP  2010-01-05  2010-01-01  2010-01-31   1001   \n",
       "3      germany  18065   FDP  2010-01-06  2010-01-01  2010-01-31   1001   \n",
       "4      germany  18083   FDP  2010-01-07  2010-01-01  2010-01-31   1001   \n",
       "\n",
       "   calendar_week  week_start    week_end  issue_ridge  issue_super  \\\n",
       "0              1  2010-01-04  2010-01-10           98           98   \n",
       "1              1  2010-01-04  2010-01-10            5           20   \n",
       "2              1  2010-01-04  2010-01-10            1            1   \n",
       "3              1  2010-01-04  2010-01-10          192          192   \n",
       "4              1  2010-01-04  2010-01-10            6            6   \n",
       "\n",
       "                                              header  \\\n",
       "0  Marc Jungnickel neuer Pressesprecher der FDP-B...   \n",
       "1                Steinmeier leidet an Politikamnesie   \n",
       "2  Nur Entlastung garantiert Erfolg bei Bekämpfun...   \n",
       "3  Westbalkan und Türkei müssen ihre Beitrittsper...   \n",
       "4  Die Sechsjährige Grundschule ist kein Erfolgsm...   \n",
       "\n",
       "                                                text  \n",
       "0  . Die Vorsitzende der FDP-Bundestagsfraktion B...  \n",
       "1  . Zu den heutigen Äußerungen von SPD-Fraktions...  \n",
       "2  . Zu den aktuellen Arbeitslosenzahlen erklärt ...  \n",
       "3  . Zu dem Vorstoß der CSU-Landesgruppe, die Dis...  \n",
       "4  . Zu den Äußerungen des Hamburger Bürgermeiste...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge data\n",
    "df_DE = df_issues.merge(df_texts, on=[\"country_name\", \"id\"], how=\"left\")\n",
    "\n",
    "df_DE = df_DE[[\n",
    "    \"country_name\", \"id\", \"party\", \"date\", \"month_start\", \"month_end\", \"month\", \"calendar_week\",\n",
    "    \"week_start\", \"week_end\", \"issue_ridge\", \"issue_super\", \"header\", \"text\"\n",
    "]]\n",
    "\n",
    "df_DE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. pre-process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    tokens = word_tokenize(text, language=\"german\")  # tokenize\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]  # remove stopwords\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  . Die Vorsitzende der FDP-Bundestagsfraktion B...   \n",
      "1  . Zu den heutigen Äußerungen von SPD-Fraktions...   \n",
      "2  . Zu den aktuellen Arbeitslosenzahlen erklärt ...   \n",
      "3  . Zu dem Vorstoß der CSU-Landesgruppe, die Dis...   \n",
      "4  . Zu den Äußerungen des Hamburger Bürgermeiste...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  vorsitzende birgit homburger teilt marc jungni...  \n",
      "1  heutigen äußerungen steinmeier erklärt stellve...  \n",
      "2  aktuellen arbeitslosenzahlen erklärt arbeitsma...  \n",
      "3  vorstoß diskussion erweiterung eu länder westb...  \n",
      "4  äußerungen hamburger bürgermeisters ole beust ...  \n"
     ]
    }
   ],
   "source": [
    "# apply preprocessing\n",
    "df_DE[\"processed_text\"] = df_DE[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# output results\n",
    "print(df_DE[[\"text\", \"processed_text\"]].iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .csv\n",
    "df_DE.to_csv(\"../data/out/df_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. document-feature matrix (DFM)\n",
    "\n",
    "_DFM_: a structured representation of text data in numerical form, used in NLP to analyze word frequencies across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  0000  000mal  001  001im  001über  007  008  00pressekonferenz  \\\n",
      "0   0    0     0       0    0      0        0    0    0                  0   \n",
      "1   0    0     0       0    0      0        0    0    0                  0   \n",
      "2   0    0     0       0    0      0        0    0    0                  0   \n",
      "3   0    0     0       0    0      0        0    0    0                  0   \n",
      "4   0    0     0       0    0      0        0    0    0                  0   \n",
      "\n",
      "   ...  ürgerten  üringen  ürümqi  šefcovic  šemeta  šešelj  šešeljevci  \\\n",
      "0  ...         0        0       0         0       0       0           0   \n",
      "1  ...         0        0       0         0       0       0           0   \n",
      "2  ...         0        0       0         0       0       0           0   \n",
      "3  ...         0        0       0         0       0       0           0   \n",
      "4  ...         0        0       0         0       0       0           0   \n",
      "\n",
      "   šešeljs  štefan  žatec  \n",
      "0        0       0      0  \n",
      "1        0       0      0  \n",
      "2        0       0      0  \n",
      "3        0       0      0  \n",
      "4        0       0      0  \n",
      "\n",
      "[5 rows x 196098 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "dfm = vectorizer.fit_transform(df_DE[\"processed_text\"])\n",
    "\n",
    "# convert to df for analysis\n",
    "df_dfm = pd.DataFrame(dfm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# output top words\n",
    "print(df_dfm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. remove most frequent and rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bereits  dafür  deutschen  deutschland  endlich  erklärt  euro  \\\n",
      "0        0      0          0            0        0        0     0   \n",
      "1        0      0          0            0        0        1     0   \n",
      "2        0      0          0            0        0        1     0   \n",
      "3        0      0          0            0        0        1     0   \n",
      "4        0      0          0            0        0        1     0   \n",
      "\n",
      "   europäischen  frage  fraktion  ...  mehr  menschen  millionen  müssen  \\\n",
      "0             0      0         0  ...     0         0          0       0   \n",
      "1             0      0         0  ...     0         1          0       0   \n",
      "2             0      0         0  ...     0         0          0       0   \n",
      "3             3      1         0  ...     0         0          0       1   \n",
      "4             0      0         0  ...     0         0          0       0   \n",
      "\n",
      "   prozent  schon  seit  spd  sprecher  sprecherin  \n",
      "0        0      0     0    0         0           0  \n",
      "1        0      0     1    4         0           0  \n",
      "2        0      1     0    0         1           0  \n",
      "3        0      0     0    0         0           0  \n",
      "4        0      0     0    0         0           0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# choose words in at least 20% and at most 70% of documents\n",
    "min_docfreq = 0.2 * len(df_dfm)\n",
    "max_docfreq = 0.7 * len(df_dfm)\n",
    "\n",
    "# sum up word occurances across documents\n",
    "word_counts = df_dfm.sum(axis=0)\n",
    "\n",
    "# filter out frequent / rare words\n",
    "df_mft = df_dfm.loc[:, (word_counts >= min_docfreq) & (word_counts <= max_docfreq)]\n",
    "\n",
    "# output top words\n",
    "print(df_mft.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .csv\n",
    "df_mft.to_csv(\"../data/out/df_mft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
